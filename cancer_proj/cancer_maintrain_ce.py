# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/cancer_maintrain_ce.ipynb.

# %% auto 0
__all__ = ['CeBarlowTwinsModel', 'BarlowTwinsCe', 'lf_ce']

# %% ../nbs/cancer_maintrain_ce.ipynb 5
from fastai.vision.all import *
from base_rbt.all import *
from .cancer_dataloading import *
from .cancer_metrics import *
from .cancer_maintrain import *

# %% ../nbs/cancer_maintrain_ce.ipynb 14
#| export


# %% ../nbs/cancer_maintrain_ce.ipynb 16
class CeBarlowTwinsModel(Module):
    """An encoder followed by a projector
    """
    def __init__(self,encoder,head):
        self.encoder = encoder
        self.head=head

    def forward(self,x):
        tem=self.encoder(x)
        return tem,self.head(tem)
    

# %% ../nbs/cancer_maintrain_ce.ipynb 17
class BarlowTwinsCe(Callback):
    order,run_valid = 9,True
    def __init__(self, aug_pipelines,n_in, lmb=5e-3,numout=10, print_augs=False):
        self.aug1, self.aug2 = aug_pipelines
        if print_augs: print(self.aug1), print(self.aug2)
        store_attr('lmb')
        self.n_in=n_in
        self.cross_entropy = CrossEntropyLossFlat()
        self.numout=numout
        
        
    def before_fit(self): 
        self.learn.loss_func = self.lf
        #nf = self.learn.model.encoder[-1].out_features
        self.nf = 8192
        self.I = torch.eye(self.nf).to(self.dls.device)


    def before_epoch(self):
        pass
  
    def before_batch(self):
        
        #TODO: Make this nicer (possibly can load in data as TensorImage(BW) or something?)
        #This is a bit of a hack. Can make this more elegant later. But in new version of FastAI
        #seems we need to compute TensorImage(BW) here, and depends on whether color or not, i.e. n_in.
        if self.n_in == 1:

            xi,xj = self.aug1(TensorImageBW(self.x)), self.aug2(TensorImageBW(self.x))
            
            #print(xi.shape)
                                    
        elif self.n_in == 3:
            
            xi,xj = self.aug1(TensorImage(self.x)), self.aug2(TensorImage(self.x))

        self.learn.xb = (torch.cat([xi, xj]),)
        
    def lf(self,pred,*yb):
        
        I=self.I
        lmb=self.lmb
        
        
        pred,out = pred[0],pred[1] #encoder and head(encoder(.))
        y = yb[0]
  
        bs,nf = pred.size(0)//2,pred.size(1)
        
        z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2
        out1,out2 = out[:bs],out[bs:]

        z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)
        z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)

        C = (z1norm.T @ z2norm) / bs 
        cdiff = (C - I)**2
        #bt_loss = (cdiff*I + cdiff*(1-I)*lmb).sum()  #bt loss
        
        rr = (cdiff*(1-I)*lmb).sum()
        
        CE1 = self.cross_entropy(out1,y)
        CE2 = self.cross_entropy(out2,y)
        
        CE = 0.5*(CE1 + CE2)
        
        loss = (1/nf)*rr + CE
        
        return loss


    @torch.no_grad()
    def show(self, n=1): 
        bs = self.learn.x.size(0)//2
        x1,x2  = self.learn.x[:bs], self.learn.x[bs:]
        idxs = np.random.choice(range(bs),n,False)
        x1 = self.aug1.decode(x1[idxs].to('cpu').clone()).clamp(0,1)
        x2 = self.aug2.decode(x2[idxs].to('cpu').clone()).clamp(0,1)
        images = []
        for i in range(n): images += [x1[i],x2[i]]
        return show_batch(x1[0], None, images, max_n=len(images), nrows=n)

# %% ../nbs/cancer_maintrain_ce.ipynb 18
def lf_ce(pred,*yb,I,lmb,t,criterion=CrossEntropyLossFlat()):
    

    pred,out = pred[0],pred[1] #encoder and head(encoder(.))
    y = yb[0]

    bs,nf = pred.size(0)//2,pred.size(1)

    z1, z2 = pred[:bs],pred[bs:] #so z1 is bs*projection_size, likewise for z2
    out1,out2 = out[:bs],out[bs:]

    z1norm = (z1 - z1.mean(0)) / z1.std(0, unbiased=False)
    z2norm = (z2 - z2.mean(0)) / z2.std(0, unbiased=False)

    C = (z1norm.T @ z2norm) / bs 
    cdiff = (C - I)**2
    #bt_loss = (cdiff*I + cdiff*(1-I)*lmb).sum()  #bt loss

    rr = (cdiff*(1-I)*lmb).sum()

    CE1 = criterion(out1,y)
    CE2 = criterion(out2,y)

    CE = 0.5*(CE1 + CE2)
    
    loss = t*rr + CE

    return loss



# %% ../nbs/cancer_maintrain_ce.ipynb 19
@patch
def lf(self:BarlowTwinsCe, pred,*yb): return lf_ce(pred,*yb,I=self.I,lmb=self.lmb,t=self.t)

# %% ../nbs/cancer_maintrain_ce.ipynb 20
@patch
def before_epoch(self:BarlowTwinsCe):
    
    self.head = nn.Linear(self.nf,self.numout) #reininitialise head before every epoch
    
    self.t=0.05
