{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/hamish-haggerty/cancer-proj/blob/main/nbs/cancer_dataloading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cancer_dataloading\n",
    "\n",
    "> Helper functions etc to load cancer data. Will also install nbdev etc if in Colab (not sure yet if I need this functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cancer_dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def colab_is_true():\n",
    "\n",
    "    try: \n",
    "        from google.colab import drive\n",
    "\n",
    "        return True \n",
    "    except ModuleNotFoundError:\n",
    "        return False\n",
    "\n",
    "def setup_colab():\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    #os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"')\n",
    "    os.system('git clone https://github.com/hamish-haggerty/cancer-proj.git')\n",
    "    os.chdir('cancer-proj')\n",
    "    os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"') #does this work?\n",
    "    os.system('pip install -e .')\n",
    "    os.system('pip install -qU nbdev')\n",
    "    os.system('nbdev_install_quarto')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    on_colab = colab_is_true()\n",
    "    if on_colab:\n",
    "        setup_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from base_rbt.base_model import * #probably don't need this whole thing...\n",
    "from base_rbt.base_linear import show_linear_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#colab\n",
    "colab_train_dir='skin_cancer_ISIC/Train'\n",
    "colab_test_dir='skin_cancer_ISIC/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#local\n",
    "local_train_dir='/Users/hamishhaggerty/Downloads/skin_cancer_ISIC/Train'\n",
    "local_test_dir='/Users/hamishhaggerty/Downloads/skin_cancer_ISIC/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#Since we have cloned repository and cd'd into it (and the data itself is not stored in the\n",
    "#repo) we need cd out of it, get the data, then cd back into the repo `cancer-proj`.\n",
    "#This is a bit annoying, can maybe remove this later\n",
    "if on_colab:\n",
    "    #os.chdir('..') #assumes we are currently in cancer-proj directory\n",
    "    train_dir = colab_train_dir\n",
    "    test_dir = colab_test_dir\n",
    "else:\n",
    "    train_dir = local_train_dir\n",
    "    test_dir = local_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#Seems all we need here is class_names?\n",
    "\n",
    "def get_file_lists(train_dir):\n",
    "\n",
    "    #train\n",
    "    class_names0 = os.listdir(train_dir)\n",
    "    class_names = sorted(class_names0)\n",
    "    num_class = len(class_names)\n",
    "    image_files = [[os.path.join(train_dir, class_name, x) \n",
    "                for x in os.listdir(os.path.join(train_dir, class_name))] \n",
    "                for class_name in class_names]\n",
    "\n",
    "    image_file_list = []\n",
    "    image_label_list = []\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        image_file_list.extend(image_files[i])\n",
    "        image_label_list.extend([i] * len(image_files[i]))\n",
    "    num_total = len(image_label_list)\n",
    "\n",
    "    return {'image_file_list':image_file_list, 'image_label_list':image_label_list, 'num_total':num_total, 'num_class':num_class, 'class_names':class_names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "\n",
    "#Helper functions to extract class names from the filenames\n",
    "import re\n",
    "def extract_text(string):\n",
    "    # Use the compile method to create a RegexObject\n",
    "    pattern = re.compile(r'/Train/(.*?)/ISIC')\n",
    "\n",
    "    # Use the search method of the RegexObject to find the pattern in the string\n",
    "    match = pattern.search(string)\n",
    "\n",
    "    # If a match is found, return the matched text\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # If no match is found, return None\n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "\n",
    "def label_func(x): return extract_text(x.as_posix())\n",
    "\n",
    "def get_difference(x1, x2):\n",
    "    return list(set(x1) - set(x2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_fnames_dict(train_dir,test_dir,class_names):\n",
    "    \"get dictionary of fnames\"\n",
    "\n",
    "        #files names\n",
    "    fnames = get_image_files(train_dir)\n",
    "    fnames.sort()\n",
    "\n",
    "    #Extract training set\n",
    "    max_num =100 #maximum number of samples in each class\n",
    "    count_dict = {i:0 for i in class_names}\n",
    "    fnames_train = []\n",
    "    for i in fnames:\n",
    "        #st=extract_text(i.as_posix())\n",
    "        st=label_func(i)\n",
    "        \n",
    "        if count_dict[st]<max_num: #no more than 100 samples per category\n",
    "            fnames_train.append(i)\n",
    "            count_dict[st]+=1\n",
    "                    \n",
    "    #We further partition fnames_train into a tune-valiation set\n",
    "    count_dict2 = {i:0 for i in class_names}\n",
    "    fnames_tune = []\n",
    "    for i in fnames_train:\n",
    "        st = label_func(i)\n",
    "        if count_dict2[st] < 0.8*count_dict[st]:\n",
    "            fnames_tune.append(i)\n",
    "            count_dict2[st]+=1\n",
    "            \n",
    "    fnames_tune.sort()\n",
    "            \n",
    "\n",
    "    fnames_valid = get_difference(fnames_train,fnames_tune)\n",
    "    fnames_valid.sort()\n",
    "\n",
    "    fnames_test = get_difference(fnames,fnames_train) + get_image_files(test_dir)\n",
    "    fnames_test.sort()\n",
    "    \n",
    "    fnames_train = fnames_tune\n",
    "    \n",
    "    \n",
    "    return {'fnames':fnames,'fnames_train':fnames_train,'fnames_tune':fnames_tune,\n",
    "            'fnames_valid':fnames_valid,\n",
    "            'fnames_test':fnames_test\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_data_dict(fnames_dict,train_dir,test_dir, #basic stuff needed\n",
    "                  device,bs_val,bs=256,bs_tune=256,size=128,n_in=3 #hyperparameters\n",
    "                 ):\n",
    "        \"get dictionary of data\"\n",
    "\n",
    "        #fnames = fnames_dict['fnames']\n",
    "        fnames_train = fnames_dict['fnames_train']\n",
    "        fnames_tune = fnames_dict['fnames_tune']\n",
    "        fnames_valid = fnames_dict['fnames_valid']\n",
    "        #fnames_test = fnames_dict['fnames_test']\n",
    "\n",
    "        item_tfms = [Resize(size)]\n",
    "\n",
    "        dls_train  = ImageDataLoaders.from_path_func(train_dir, fnames_train, label_func,\n",
    "                                        bs=bs,\n",
    "                                        item_tfms=item_tfms,\n",
    "                                        valid_pct=0,\n",
    "                                        device=device,\n",
    "                                        num_workers=12*(device=='cuda')\n",
    "                                        )\n",
    "        x,y = dls_train.one_batch()\n",
    "\n",
    "        dls_tune = ImageDataLoaders.from_path_func(train_dir, fnames_tune, label_func,\n",
    "                                        bs=bs_tune,\n",
    "                                        item_tfms=item_tfms,\n",
    "                                        valid_pct=0,\n",
    "                                        device=device,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=12*(device=='cuda'),\n",
    "                                        )\n",
    "        xtune,ytune = dls_tune.one_batch()\n",
    "\n",
    "        dls_valid  = ImageDataLoaders.from_path_func(train_dir, fnames_valid, label_func,\n",
    "                                        bs=bs_val,\n",
    "                                        item_tfms=item_tfms,\n",
    "                                        valid_pct=0,\n",
    "                                        num_workers=12*(device=='cuda')\n",
    "                                        )\n",
    "        \n",
    "        xval,yval = dls_valid.one_batch()\n",
    "\n",
    "        vocab = dls_valid.vocab\n",
    "\n",
    "        #return the dls etc\n",
    "        return {'dls_train':dls_train,'dls_tune':dls_tune,'dls_valid':dls_valid,\n",
    "                'x':x,'y':y,'xval':xval,'yval':yval,'xtune':xtune,'ytune':ytune,\n",
    "                'vocab':vocab\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_fnames_dls_dict(train_dir,test_dir,\n",
    "                        device,bs_val,bs=256,bs_tune=256,size=128,n_in=3,\n",
    "                        ):\n",
    "\n",
    "    \"Wrapper that returns a dictionary with the fnames, dls etc\"\n",
    "\n",
    "    #do stuff\n",
    "\n",
    "    class_names = get_file_lists(train_dir)['class_names']\n",
    "    \n",
    "    fnames_dict = get_fnames_dict(train_dir,test_dir,class_names)\n",
    "\n",
    "    data_dict = get_data_dict(fnames_dict,train_dir,test_dir, #basic stuff needed\n",
    "                  device,bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=n_in #hyperparameters\n",
    "                 )\n",
    "\n",
    "    d = {**fnames_dict,**data_dict}\n",
    "    \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_dict_to_gdrive(d,directory, filename):\n",
    "    #e.g. directory='/content/drive/My Drive/random_initial_weights'\n",
    "    filepath = directory + '/' + filename + '.pkl'\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(d, f)\n",
    "\n",
    "def load_dict_from_gdrive(directory,filename):\n",
    "    #e.g. directory='/content/drive/My Drive/random_initial_weights'\n",
    "    filepath = directory + '/' + filename + '.pkl'\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_np(tensor_image):\n",
    "    return tensor_image.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def seed_everything(TORCH_SEED):\n",
    "    random.seed(TORCH_SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(TORCH_SEED)\n",
    "    np.random.seed(TORCH_SEED)\n",
    "    torch.manual_seed(TORCH_SEED)\n",
    "    torch.cuda.manual_seed_all(TORCH_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#How we want to use\n",
    "\n",
    "#define general hps\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "bs=256\n",
    "bs_tune=256\n",
    "#size=128\n",
    "size=128\n",
    "bs_val=174\n",
    "#can define other hyperparameters here\n",
    "\n",
    "#get the data dictionary\n",
    "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
    "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
    "\n",
    "#get the dataloaders and other stuff \n",
    "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
    "x,y = data_dict['x'],data_dict['y']\n",
    "xval,yval = data_dict['xval'],data_dict['yval']\n",
    "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
    "vocab = data_dict['vocab']\n",
    "\n",
    "#If we want to write some tests (make sure the data is same every time etc):\n",
    "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "test_eq(fnames_train[0].as_posix().split('/')[-1],'ISIC_0025780.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tests: make sure that data is the same each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "#So we can check that e.g. loading on colab will give the same results\n",
    "\n",
    "def test_fnames(_fnames):\n",
    "    melanoma_names=[]\n",
    "    basalcellcarcinoma_names=[]\n",
    "    actinickeratosis_names=[]\n",
    "\n",
    "    for i in _fnames:\n",
    "\n",
    "        if 'melanoma' in i.as_posix(): melanoma_names.append(i.as_posix().split('/')[-1])\n",
    "\n",
    "        if 'basal cell carcinoma' in i.as_posix(): basalcellcarcinoma_names.append(i.as_posix().split('/')[-1])\n",
    "\n",
    "        if 'actinic keratosis' in i.as_posix(): actinickeratosis_names.append(i.as_posix().split('/')[-1])\n",
    "    \n",
    "    return melanoma_names,basalcellcarcinoma_names,actinickeratosis_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "melanoma_names_train=['ISIC_0000139.jpg','ISIC_0000141.jpg','ISIC_0000142.jpg','ISIC_0000143.jpg','ISIC_0000144.jpg','ISIC_0000145.jpg','ISIC_0000146.jpg','ISIC_0000147.jpg','ISIC_0000148.jpg','ISIC_0000149.jpg','ISIC_0000150.jpg','ISIC_0000151.jpg','ISIC_0000152.jpg','ISIC_0000153.jpg','ISIC_0000154.jpg','ISIC_0000155.jpg','ISIC_0000156.jpg','ISIC_0000157.jpg','ISIC_0000158.jpg','ISIC_0000159.jpg','ISIC_0000160.jpg','ISIC_0000161.jpg','ISIC_0000162.jpg','ISIC_0000163.jpg','ISIC_0000164.jpg','ISIC_0000165.jpg','ISIC_0000166.jpg','ISIC_0000167.jpg','ISIC_0000168.jpg','ISIC_0000169.jpg','ISIC_0000170.jpg','ISIC_0000171.jpg','ISIC_0000172.jpg','ISIC_0000173.jpg','ISIC_0000174.jpg','ISIC_0000175.jpg','ISIC_0000176.jpg','ISIC_0000278.jpg','ISIC_0000279.jpg','ISIC_0000280.jpg','ISIC_0000285.jpg','ISIC_0000288.jpg','ISIC_0000289.jpg','ISIC_0000291.jpg','ISIC_0000292.jpg','ISIC_0000293.jpg','ISIC_0000294.jpg','ISIC_0000295.jpg','ISIC_0000296.jpg','ISIC_0000297.jpg','ISIC_0000298.jpg','ISIC_0000299.jpg','ISIC_0000300.jpg','ISIC_0000301.jpg','ISIC_0000302.jpg','ISIC_0000303.jpg','ISIC_0000304.jpg','ISIC_0000305.jpg','ISIC_0000306.jpg','ISIC_0000307.jpg','ISIC_0000308.jpg','ISIC_0000309.jpg','ISIC_0000310.jpg','ISIC_0000311.jpg','ISIC_0000312.jpg','ISIC_0000313.jpg','ISIC_0000314.jpg','ISIC_0000390.jpg','ISIC_0000393.jpg','ISIC_0000394.jpg','ISIC_0000395.jpg','ISIC_0000398.jpg','ISIC_0000399.jpg','ISIC_0000400.jpg','ISIC_0000401.jpg','ISIC_0000402.jpg','ISIC_0000404.jpg','ISIC_0000405.jpg','ISIC_0000406.jpg','ISIC_0000410.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "actinickeratosis_names_valid=['ISIC_0030491.jpg','ISIC_0030586.jpg','ISIC_0030655.jpg','ISIC_0030730.jpg','ISIC_0030825.jpg','ISIC_0030826.jpg','ISIC_0030877.jpg','ISIC_0031040.jpg','ISIC_0031108.jpg','ISIC_0031228.jpg','ISIC_0031292.jpg','ISIC_0031335.jpg','ISIC_0031381.jpg','ISIC_0031430.jpg','ISIC_0031506.jpg','ISIC_0031609.jpg','ISIC_0031823.jpg','ISIC_0031922.jpg','ISIC_0031993.jpg','ISIC_0032135.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to put at the top of every notebook within which we load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#the main point of this is to test that we get the same on colab as locally\n",
    "#the key is that we sort fnames first!!\n",
    "_melanoma_names_train,_basalcellcarcinoma_names_train,_actinickeratosis_names_train = test_fnames(fnames_train)\n",
    "_melanoma_names_valid,_basalcellcarcinoma_names_valid,_actinickeratosis_names_valid = test_fnames(fnames_valid)\n",
    "\n",
    "\n",
    "test_eq(melanoma_names_train,_melanoma_names_train)\n",
    "test_eq(actinickeratosis_names_valid,_actinickeratosis_names_valid)\n",
    "\n",
    "test_eq(melanoma_names_train[0],'ISIC_0000139.jpg')\n",
    "test_eq(_basalcellcarcinoma_names_valid[5],'ISIC_0026439.jpg')\n",
    "test_eq(actinickeratosis_names_valid[-1],'ISIC_0032135.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#Some simple tests\n",
    "\n",
    "#test shapes\n",
    "test_eq(x.shape[0],bs)\n",
    "test_eq(xtune.shape[0],bs_tune)\n",
    "test_eq(xval.shape[0],bs_val)\n",
    "\n",
    "#test yval has same number of instances of each class each time...\n",
    "if yval.shape[0] == 174:\n",
    "    test_eq(yval.sum().item(),688.)\n",
    "    \n",
    "#TODO: Write tests that check that the fnames are the same every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_resnet_encoder(model,n_in=3):\n",
    "    model = create_body(model, n_in=n_in, pretrained=False, cut=len(list(model.children()))-1)\n",
    "    model.add_module('flatten', torch.nn.Flatten())\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(which_model,device,ps=8192,n_in=3):\n",
    "\n",
    "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
    "\n",
    "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "    \n",
    "    elif which_model == 'no_pretrain': model = resnet50()\n",
    "\n",
    "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
    "    #(which themselves are either pretrained or not)\n",
    "    encoder = get_resnet_encoder(model)\n",
    "\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
    "\n",
    "    if device == 'cuda':\n",
    "        model.cuda()\n",
    "        encoder.cuda()\n",
    "\n",
    "\n",
    "    return model,encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#test\n",
    "\n",
    "ps=8192\n",
    "device=device=default_device().type\n",
    "cuda=(device=='cuda')\n",
    "\n",
    "model,encoder = create_model(which_model='bt_pretrain',device=device)\n",
    "for p in model.parameters():\n",
    "    test_eq(p.requires_grad,True)\n",
    "\n",
    "#| hide\n",
    "\n",
    "def sum_params(model):\n",
    "\n",
    "    s=0\n",
    "    for p in model.parameters():\n",
    "        s+=p.sum()\n",
    "    return s.item()\n",
    "\n",
    "\n",
    "def colab_tests(): #we run out of memory locally with these\n",
    "\n",
    "    #Test that shape of encoder is 2048\n",
    "    _,e = create_model(which_model='bt_pretrain',device=device)\n",
    "    test_eq(e(x).shape[1],2048) \n",
    "\n",
    "    #Test that pretrained models (encoders) have the same weights (roughyl) each time\n",
    "    _,e = create_model(which_model='bt_pretrain',device=device)\n",
    "    test_eq((sum_params(e)-175864.4062)<0.001,True)\n",
    "\n",
    "    _,e = create_model(which_model='supervised_pretrain',device=device)\n",
    "    test_eq((sum_params(e)-39438.5078125)<0.001,True)\n",
    "\n",
    "    #Test that non-pretrained model has diff (i.e. random) weights each time\n",
    "    _,e1 = create_model(which_model='no_pretrain',device=device)\n",
    "    _,e2 = create_model(which_model='no_pretrain',device=device)\n",
    "    test_ne(sum_params(e1),sum_params(e2))\n",
    "\n",
    "\n",
    "\n",
    "if on_colab:\n",
    "    colab_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "BYOL_Augs = dict(flip_p1=0.5,flip_p2=0.5,jitter_p1=0.8,jitter_p2=0.8,bw_p1=0.2,\n",
    "                bw_p2=0.2,blur_p1=1.0,blur_p2=0.1,sol_p1=0.0,sol_p2=0.2,noise_p1=0.0,\n",
    "                noise_p2=0.0,resize_scale=(0.7, 1.0),resize_ratio=(3/4, 4/3),rotate_deg=45.0,\n",
    "                rotate_p=0.5,blur_r=(0.1,2),blur_s=13,sol_t=0.1,sol_a=0.1,noise_std=0.1 \n",
    "                )\n",
    "\n",
    "\n",
    "TUNE_Augs=dict(blur_r = BYOL_Augs['blur_r'],blur_s = BYOL_Augs['blur_s'], flip_p=0.25,\n",
    "                rotate_p=0.25,jitter_p=0.0,bw_p=0.0,blur_p=0.0,resize_scale=(0.7, 1.0),\n",
    "                resize_ratio=(3/4, 4/3),rotate_deg=45.0\n",
    "                )\n",
    "\n",
    "Val_Augs = dict(TUNE_Augs)\n",
    "\n",
    "\n",
    "def create_aug_pipelines(size,device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs):\n",
    "    \"Create the BT pipelines, the tune and val pipelines\"\n",
    "\n",
    "    aug_dict = {}\n",
    "\n",
    "    aug_pipelines_1 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        flip_p=Augs['flip_p1'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p1'],\n",
    "                        jitter_p=Augs['jitter_p1'], bw_p=Augs['bw_p1'], blur_p=Augs['blur_p1'],\n",
    "                        sol_p=Augs['sol_p1'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None, cuda=(device=='cuda'))\n",
    "\n",
    "    aug_pipelines_2 = get_barlow_twins_aug_pipelines(size=size,\n",
    "                        rotate=True,jitter=True,noise=True,bw=True,blur=True,solar=True, #Whether to use aug or not\n",
    "                        resize_scale=Augs['resize_scale'],resize_ratio=Augs['resize_ratio'],\n",
    "                        noise_std=Augs['noise_std'], rotate_deg=Augs['rotate_deg'],\n",
    "                        blur_r=Augs['blur_r'],blur_s=Augs['blur_s'],sol_t=Augs['sol_t'],sol_a=Augs['sol_a'],\n",
    "                        flip_p=Augs['flip_p2'], rotate_p=Augs['rotate_p'],noise_p=Augs['noise_p2'],\n",
    "                        jitter_p=Augs['jitter_p2'], bw_p=Augs['bw_p2'], blur_p=Augs['blur_p2'],\n",
    "                        sol_p=Augs['sol_p2'], #prob of performing aug\n",
    "                        same_on_batch=False,stats=None, cuda=(device=='cuda'))\n",
    "\n",
    "    aug_pipelines = [aug_pipelines_1,aug_pipelines_2]\n",
    "\n",
    "\n",
    "    aug_pipelines_tune =  [get_barlow_twins_aug_pipelines(size=size,\n",
    "                    rotate=True,jitter=True,noise=False,bw=True,blur=True,solar=False, #Whether to use aug or not\n",
    "                    resize_scale=TUNE_Augs['resize_scale'],resize_ratio=TUNE_Augs['resize_ratio'],noise_std=None,\n",
    "                    blur_r=TUNE_Augs['blur_r'],blur_s=TUNE_Augs['blur_s'], rotate_deg=TUNE_Augs['rotate_deg'],\n",
    "                    sol_t=None,sol_a=None, #hps of augs\n",
    "                    flip_p=TUNE_Augs['flip_p'], rotate_p=TUNE_Augs['rotate_p'],noise_p=0.0, jitter_p=TUNE_Augs['jitter_p'],\n",
    "                    bw_p=TUNE_Augs['bw_p'], blur_p=TUNE_Augs['blur_p'],sol_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=None, cuda=(device=='cuda'))]#,P=0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    aug_pipelines_test =  [get_barlow_twins_aug_pipelines(size=size,\n",
    "                    rotate=True,jitter=True,noise=False,bw=True,blur=True,solar=False, #Whether to use aug or not\n",
    "                    resize_scale=Val_Augs['resize_scale'],resize_ratio=Val_Augs['resize_ratio'],noise_std=None,\n",
    "                    blur_r=Val_Augs['blur_r'],blur_s=Val_Augs['blur_s'], rotate_deg=Val_Augs['rotate_deg'],\n",
    "                    sol_t=None,sol_a=None, #hps of augs\n",
    "                    flip_p=Val_Augs['flip_p'], rotate_p=Val_Augs['rotate_p'],noise_p=0.0, jitter_p=Val_Augs['jitter_p'],\n",
    "                    bw_p=Val_Augs['bw_p'], blur_p=Val_Augs['blur_p'],sol_p=0.0, #prob of performing aug\n",
    "                    same_on_batch=False,stats=None, cuda=(device=='cuda'))]#,P=0.0)\n",
    "\n",
    "    aug_dict['aug_pipelines'] = aug_pipelines\n",
    "    aug_dict['aug_pipelines_tune'] = aug_pipelines_tune\n",
    "    aug_dict['aug_pipelines_test'] = aug_pipelines_test\n",
    "\n",
    "    return aug_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "device='cpu'\n",
    "aug_dict = create_aug_pipelines(size=size,device=device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "show_bt_batch(dls=dls_train,n_in=3,aug=aug_dict['aug_pipelines'],n=2,print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "show_linear_batch(dls=dls_tune,n_in=3,aug=aug_dict['aug_pipelines_tune'],n=2,print_augs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#test: We copy paste the BYOL augs we have been using (which we know give good performance)\n",
    "\n",
    "#########################\n",
    "flip_p1 = 0.5\n",
    "flip_p2 = 0.5\n",
    "\n",
    "##byol defaults\n",
    "jitter_p1 = 0.8\n",
    "jitter_p2 = 0.8\n",
    "\n",
    "#byol defaults\n",
    "bw_p1 = 0.2\n",
    "bw_p2 = 0.2\n",
    "\n",
    "# bw_p1 = 0.0\n",
    "# bw_p2 = 0.0\n",
    "\n",
    "blur_p1 = 1.0\n",
    "blur_p2 = 0.1\n",
    "\n",
    "sol_p1 = 0.0\n",
    "sol_p2 = 0.2 #BYOL default\n",
    "#sol_p2 = 0.0\n",
    "\n",
    "noise_p1 = 0.0\n",
    "noise_p2 = 0.0\n",
    "#Noise isn't included! So we exclude for now\n",
    "\n",
    "#Normalization?? None for now as it looks weird\n",
    "\n",
    "resize_scale=(0.7, 1.0)\n",
    "resize_ratio=(3/4, 4/3)\n",
    "\n",
    "#Rotation isn't included in ImageNet. We just include some. \n",
    "rotate_deg = 45\n",
    "rotate_p = 0.5\n",
    "\n",
    "##Values of hps:\n",
    "blur_r = (0.1,2) #like BYOL\n",
    "blur_s = 13 #as ~ 128/10 like BYOL\n",
    "\n",
    "#blur_r = (0.1,4) #like BYOL\n",
    "#blur_s = 13 #as ~ 128/10 like BYOL\n",
    "\n",
    "\n",
    "sol_t = 0.1 #kornia defaults. Not sure still about BYOL defaults.\n",
    "sol_a = 0.1\n",
    "\n",
    "noise_std = 0.1 \n",
    "\n",
    "###################\n",
    "\n",
    "###################\n",
    "\n",
    "\n",
    "for k in BYOL_Augs.keys():\n",
    "    test_eq(BYOL_Augs[k],locals()[k])\n",
    "\n",
    "#Hyperparams for fine-tuning augmentations. We use: blur; jitter; grayscale (maybe) and soft augs.\n",
    "blur_r = blur_r\n",
    "blur_s = blur_s\n",
    "flip_p = 0.25\n",
    "rotate_p = 0.25\n",
    "jitter_p = 0.0\n",
    "bw_p = 0.0\n",
    "blur_p = 0.0\n",
    "#########################\n",
    "\n",
    "for k in TUNE_Augs.keys():\n",
    "\n",
    "    test_eq(TUNE_Augs[k],locals()[k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1096656cc7b047a29b0646ec11c2b3d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c9e061ac3b043fe97595065f2a7a034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac2f687d5bee42a1bf2b194fafc59cfd",
      "placeholder": "​",
      "style": "IPY_MODEL_d15bb144361b4cdb802db6578a6b5ce8",
      "value": " 97.8M/97.8M [00:01&lt;00:00, 62.4MB/s]"
     }
    },
    "70b5b9fefb8e4b3b89e3eb8caa727ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f16711e73770438ba0238d25dfae5ed3",
      "max": 102540417,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86a691ddc492425c9923445c8d8f0ae1",
      "value": 102540417
     }
    },
    "79091361d0924e7690ab446eb620e8b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84c9bf9b32514273b00e53158d0436df",
       "IPY_MODEL_70b5b9fefb8e4b3b89e3eb8caa727ea1",
       "IPY_MODEL_2c9e061ac3b043fe97595065f2a7a034"
      ],
      "layout": "IPY_MODEL_1096656cc7b047a29b0646ec11c2b3d6"
     }
    },
    "84c9bf9b32514273b00e53158d0436df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b371ae4a3f0440709233c0837bbeaf86",
      "placeholder": "​",
      "style": "IPY_MODEL_c3966ba4d318417c98097b5a61f20a03",
      "value": "100%"
     }
    },
    "86a691ddc492425c9923445c8d8f0ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ac2f687d5bee42a1bf2b194fafc59cfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b371ae4a3f0440709233c0837bbeaf86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3966ba4d318417c98097b5a61f20a03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d15bb144361b4cdb802db6578a6b5ce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f16711e73770438ba0238d25dfae5ed3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
