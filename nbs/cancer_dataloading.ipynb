{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cancer_dataloading\n",
    "\n",
    "> Helper functions etc to load cancer data. Will also install nbdev etc if in Colab (not sure yet if I need this functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cancer_dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !unzip -q \"/content/drive/My Drive/archive (1).zip\"\n",
    "except ModuleNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# try:\n",
    "\n",
    "#     from nbdev.showdoc import *\n",
    "\n",
    "# except ModuleNotFoundError:\n",
    "                        \n",
    "#     !pip install nbdev\n",
    "#     !nbdev_install_quarto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#TODO: Refactor base_rbt library such that can import in one line \n",
    "\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# try: \n",
    "from base_rbt.base_model import * \n",
    "from base_rbt.base_lf import *\n",
    "from base_rbt.base_linear import *\n",
    "from base_rbt.helper import *\n",
    "\n",
    "# except  ModuleNotFoundError:\n",
    "#     !pip install -qU git+https://github.com/hamish-haggerty/base_rbt.git#egg='base_rbt'\n",
    "#     from base_rbt.base_model import * \n",
    "#     from base_rbt.base_lf import *\n",
    "#     from base_rbt.base_linear import *\n",
    "#     from base_rbt.helper import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#colab\n",
    "colab_train_dir='skin_cancer_ISIC/Train'\n",
    "colab_test_dir='skin_cancer_ISIC/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#local\n",
    "local_train_dir='/Users/hamishhaggerty/Downloads/skin_cancer_ISIC/Train'\n",
    "local_test_dir='/Users/hamishhaggerty/Downloads/skin_cancer_ISIC/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#Seems all we need here is class_names?\n",
    "\n",
    "def get_file_lists(train_dir):\n",
    "\n",
    "    #train\n",
    "    class_names0 = os.listdir(train_dir)\n",
    "    class_names = sorted(class_names0)\n",
    "    num_class = len(class_names)\n",
    "    image_files = [[os.path.join(train_dir, class_name, x) \n",
    "                for x in os.listdir(os.path.join(train_dir, class_name))] \n",
    "                for class_name in class_names]\n",
    "\n",
    "    image_file_list = []\n",
    "    image_label_list = []\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        image_file_list.extend(image_files[i])\n",
    "        image_label_list.extend([i] * len(image_files[i]))\n",
    "    num_total = len(image_label_list)\n",
    "\n",
    "    return {'image_file_list':image_file_list, 'image_label_list':image_label_list, 'num_total':num_total, 'num_class':num_class, 'class_names':class_names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#Helper functions to extract class names from the filenames\n",
    "import re\n",
    "def extract_text(string):\n",
    "    # Use the compile method to create a RegexObject\n",
    "    pattern = re.compile(r'/Train/(.*?)/ISIC')\n",
    "\n",
    "    # Use the search method of the RegexObject to find the pattern in the string\n",
    "    match = pattern.search(string)\n",
    "\n",
    "    # If a match is found, return the matched text\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # If no match is found, return None\n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "\n",
    "def label_func(x): return extract_text(x.as_posix())\n",
    "\n",
    "def get_difference(x1, x2):\n",
    "    return list(set(x1) - set(x2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_fnames_dict(train_dir,test_dir,class_names):\n",
    "    \"get dictionary of fnames\"\n",
    "\n",
    "        #files names\n",
    "    fnames = get_image_files(train_dir)\n",
    "\n",
    "    #Extract training set\n",
    "    max_num =100 #maximum number of samples in each class\n",
    "    count_dict = {i:0 for i in class_names}\n",
    "    fnames_train = []\n",
    "    for i in fnames:\n",
    "        #st=extract_text(i.as_posix())\n",
    "        st=label_func(i)\n",
    "        \n",
    "        if count_dict[st]<max_num: #no more than 100 samples per category\n",
    "            fnames_train.append(i)\n",
    "            count_dict[st]+=1\n",
    "                    \n",
    "    #We further partition fnames_train into a tune-valiation set\n",
    "    count_dict2 = {i:0 for i in class_names}\n",
    "    fnames_tune = []\n",
    "    for i in fnames_train:\n",
    "        st = label_func(i)\n",
    "        if count_dict2[st] < 0.8*count_dict[st]:\n",
    "            fnames_tune.append(i)\n",
    "            count_dict2[st]+=1\n",
    "            \n",
    "\n",
    "    fnames_valid = get_difference(fnames_train,fnames_tune)\n",
    "\n",
    "    fnames_test = get_difference(fnames,fnames_train) + get_image_files(test_dir)\n",
    "\n",
    "    return {'fnames':fnames,'fnames_train':fnames_train,'fnames_tune':fnames_tune,\n",
    "            'fnames_valid':fnames_valid,\n",
    "            'fnames_test':fnames_test\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_data_dict(fnames_dict,train_dir,test_dir, #basic stuff needed\n",
    "                  device,bs_val,bs=256,bs_tune=256,size=128,n_in=3 #hyperparameters\n",
    "                 ):\n",
    "        \"get dictionary of data\"\n",
    "\n",
    "        #fnames = fnames_dict['fnames']\n",
    "        fnames_train = fnames_dict['fnames_train']\n",
    "        fnames_tune = fnames_dict['fnames_tune']\n",
    "        fnames_valid = fnames_dict['fnames_valid']\n",
    "        #fnames_test = fnames_dict['fnames_test']\n",
    "\n",
    "        item_tfms = [Resize(size)]\n",
    "\n",
    "        dls_train  = ImageDataLoaders.from_path_func(train_dir, fnames_train, label_func,\n",
    "                                        bs=bs,\n",
    "                                        item_tfms=item_tfms,\n",
    "                                        valid_pct=0,\n",
    "                                        device=device,\n",
    "                                        num_workers=12*(device=='cuda')\n",
    "                                        )\n",
    "        x,y = dls_train.one_batch()\n",
    "\n",
    "        dls_tune = ImageDataLoaders.from_path_func(train_dir, fnames_tune, label_func,\n",
    "                                        bs=bs_tune,\n",
    "                                        item_tfms=item_tfms,\n",
    "                                        valid_pct=0,\n",
    "                                        device=device,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=12*(device=='cuda'),\n",
    "                                        )\n",
    "        xtune,ytune = dls_tune.one_batch()\n",
    "\n",
    "        dls_valid  = ImageDataLoaders.from_path_func(train_dir, fnames_valid, label_func,\n",
    "                                        bs=bs_val,\n",
    "                                        item_tfms=item_tfms,\n",
    "                                        valid_pct=0,\n",
    "                                        num_workers=12*(device=='cuda')\n",
    "                                        )\n",
    "        \n",
    "        xval,yval = dls_valid.one_batch()\n",
    "\n",
    "        vocab = dls_valid.vocab\n",
    "\n",
    "        #return the dls etc\n",
    "        return {'dls_train':dls_train,'dls_tune':dls_tune,'dls_valid':dls_valid,\n",
    "                'x':x,'y':y,'xval':xval,'yval':yval,'xtune':xtune,'ytune':ytune,\n",
    "                'vocab':vocab\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_fnames_dls_dict(train_dir,test_dir,\n",
    "                        device,bs_val,bs=256,bs_tune=256,size=128,n_in=3,\n",
    "                        ):\n",
    "\n",
    "    \"Wrapper that returns a dictionary with the fnames, dls etc\"\n",
    "\n",
    "    #do stuff\n",
    "\n",
    "    class_names = get_file_lists(train_dir)['class_names']\n",
    "    \n",
    "    fnames_dict = get_fnames_dict(train_dir,test_dir,class_names)\n",
    "\n",
    "    data_dict = get_data_dict(fnames_dict,train_dir,test_dir, #basic stuff needed\n",
    "                  device,bs_val,bs=256,bs_tune=256,size=128,n_in=3 #hyperparameters\n",
    "                 )\n",
    "\n",
    "    d = {**fnames_dict,**data_dict}\n",
    "    \n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#How we want to use\n",
    "\n",
    "#define general hps\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "bs=256\n",
    "bs_tune=256\n",
    "size=128\n",
    "bs_val=174\n",
    "train_dir = local_train_dir\n",
    "test_dir = local_test_dir\n",
    "#can define other hyperparameters here\n",
    "\n",
    "#get the data dictionary\n",
    "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
    "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
    "\n",
    "#get the dataloaders and other stuff \n",
    "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
    "x,y = data_dict['x'],data_dict['y']\n",
    "xval,yval = data_dict['xval'],data_dict['yval']\n",
    "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
    "vocab = data_dict['vocab']\n",
    "\n",
    "#If we want to write some tests (make sure the data is same every time etc):\n",
    "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#Some simple tests\n",
    "\n",
    "#test shapes\n",
    "test_eq(x.shape[0],bs)\n",
    "test_eq(xtune.shape[0],bs_tune)\n",
    "test_eq(xval.shape[0],bs_val)\n",
    "\n",
    "#test yval has same number of instances of each class each time...\n",
    "if yval.shape[0] == 174:\n",
    "    test_eq(yval.sum().item(),688.)\n",
    "\n",
    "#TODO: Write tests that check that the fnames are the same every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_resnet_encoder(model,n_in=3):\n",
    "    model = create_body(model, n_in=n_in, pretrained=False, cut=len(list(model.children()))-1)\n",
    "    model.add_module('flatten', torch.nn.Flatten())\n",
    "    return model\n",
    "\n",
    "def create_model(which_model=None,n_in=3):\n",
    "\n",
    "    #pretrained=True if 'which_model' in ['bt_pretrain', 'supervised_pretrain'] else False\n",
    "\n",
    "    if which_model == 'bt_pretrain': model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
    "    \n",
    "    elif which_model == 'no_pretrain': model = resnet50()\n",
    "\n",
    "    elif which_model == 'supervised_pretrain': model = resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "    #ignore the 'pretrained=False' argument here. Just means we use the weights above \n",
    "    #(which themselves are either pretrained or not)\n",
    "    encoder = get_resnet_encoder(model)\n",
    "\n",
    "    model = create_barlow_twins_model(encoder, hidden_size=ps,projection_size=ps,nlayers=3)\n",
    "\n",
    "    if device == 'cuda':\n",
    "        model.cuda()\n",
    "        encoder.cuda()\n",
    "\n",
    "\n",
    "    return model,encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#test\n",
    "\n",
    "\n",
    "ps=8192\n",
    "device=device=default_device().type\n",
    "cuda=(device=='cuda')\n",
    "\n",
    "model,encoder = create_model(which_model='bt_pretrain')\n",
    "for p in model.parameters():\n",
    "    test_eq(p.requires_grad,True)\n",
    "\n",
    "#| hide\n",
    "\n",
    "def sum_params(model):\n",
    "\n",
    "    s=0\n",
    "    for p in model.parameters():\n",
    "        s+=p.sum()\n",
    "    return s.item()\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "\n",
    "    #Test that shape of encoder is 2048\n",
    "    _,e = create_model(which_model='bt_pretrain')\n",
    "    test_eq(e(x).shape[1],2048) \n",
    "\n",
    "    #Test that pretrained models (encoders) have the same weights (roughyl) each time\n",
    "    _,e = create_model(which_model='bt_pretrain')\n",
    "    test_eq((sum_params(e)-175864.4062)<0.001,True)\n",
    "\n",
    "    _,e = create_model(which_model='supervised_pretrain')\n",
    "    test_eq((sum_params(e)-39438.5078125)<0.001,True)\n",
    "\n",
    "    #Test that non-pretrained model has diff (i.e. random) weights each time\n",
    "    _,e1 = create_model(which_model='no_pretrain')\n",
    "    _,e2 = create_model(which_model='no_pretrain')\n",
    "    test_ne(sum_params(e1),sum_params(e2))\n",
    "\n",
    "if device == 'cuda':\n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renamelater",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
