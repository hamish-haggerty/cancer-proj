{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cancer_maintrain\n",
    "\n",
    "> Please add a description. Don't forgot to edit the below cell!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cancer_maintrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup: Surely there is a way to get rid of having to put this cell everywhere. hmmm.\n",
    "\n",
    "Or we can just copy paste / delete this in and out when needed. Either way, getting close to a decent workable workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def colab_is_true():\n",
    "\n",
    "    try: \n",
    "        from google.colab import drive\n",
    "\n",
    "        return True \n",
    "    except ModuleNotFoundError:\n",
    "        return False\n",
    "\n",
    "def setup_colab():\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    #os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"')\n",
    "    os.system('git clone https://github.com/hamish-haggerty/cancer-proj.git')\n",
    "    os.chdir('cancer-proj')\n",
    "    os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"') #does this work?\n",
    "    os.system('pip install -e .')\n",
    "    os.system('pip install -qU nbdev')\n",
    "    os.system('nbdev_install_quarto')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    on_colab = colab_is_true()\n",
    "    if on_colab:\n",
    "        setup_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cancer_proj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#| export\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbase_rbt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcancer_proj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcancer_dataloading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcancer_proj\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcancer_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cancer_proj'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from fastai.vision.all import *\n",
    "#| export\n",
    "from base_rbt.all import *\n",
    "from cancer_proj.cancer_dataloading import *\n",
    "from cancer_proj.cancer_metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now just get the data however it works. Will fix this later. But want to get `main_train` working for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#Since we have cloned repository and cd'd into it (and the data itself is not stored in the\n",
    "#repo) we need cd out of it, get the data, then cd back into the repo `cancer-proj`.\n",
    "#This is a bit annoying, can maybe remove this later\n",
    "if on_colab:\n",
    "    #os.chdir('..') #assumes we are currently in cancer-proj directory\n",
    "    train_dir = colab_train_dir\n",
    "    test_dir = colab_test_dir\n",
    "else:\n",
    "    train_dir = local_train_dir\n",
    "    test_dir = local_test_dir\n",
    "    \n",
    "\n",
    "\n",
    "#define general hps\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "bs=256\n",
    "bs_tune=256\n",
    "size=128\n",
    "bs_val=174\n",
    "\n",
    "#get the data dictionary\n",
    "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
    "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
    "\n",
    "#get the dataloaders\n",
    "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
    "x,y = data_dict['x'],data_dict['y']\n",
    "xval,yval = data_dict['xval'],data_dict['yval']\n",
    "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
    "vocab = data_dict['vocab']\n",
    "\n",
    "#If we want to write some tests (make sure the data is same every time etc):\n",
    "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']\n",
    "\n",
    "# if on_colab:\n",
    "#     os.chdir('cancer-proj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load aug pipelines here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "\n",
    "aug_dict = create_aug_pipelines(size=size,device=device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs)\n",
    "aug_pipelines = aug_dict['aug_pipelines']\n",
    "aug_pipelines_tune = aug_dict['aug_pipelines_tune']\n",
    "aug_pipelines_test = aug_dict['aug_pipelines_test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "show_bt_batch(dls=dls_train,aug=aug_pipelines,n_in=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "show_linear_batch(dls=dls_tune,n_in=3,aug=aug_pipelines_tune,n=2,print_augs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Can probably put this in `dataloading`. No need to clog this notebook up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "@patch\n",
    "def lf(self:BarlowTwins, pred,*yb): return lf_bt(pred,I=self.I,lmb=self.lmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main training api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import itertools\n",
    "initialweights = ['no_pretrain','supervised_pretrain']\n",
    "fitpolicy = ['fit_one_cycle','fit']\n",
    "\n",
    "#cartesian product of hps\n",
    "MyTuple = namedtuple('MyTuple', 'initialweights fitpolicy')\n",
    "HPs = [MyTuple(x,y) for x,y in list(itertools.product(initialweights, fitpolicy))]\n",
    "\n",
    "for hp in HPs:\n",
    "    print(hp.initialweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class main_train:\n",
    "    \"\"\"Instantiate and (optionally) train the encoder. Then fine-tune the supervised model. \n",
    "    Outputs metrics on validation data\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dls_train, #used for training BT (if pretrain=True)\n",
    "                 dls_tune , #used for tuning\n",
    "                 dls_valid, #used to compute metrics / evaluate results. \n",
    "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
    "                 yval,\n",
    "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
    "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
    "                 aug_pipelines_test, #test (or valid) time augmentations \n",
    "                 initial_weights, #Which initial weights to use\n",
    "                 pretrain, #Whether to fit BT\n",
    "                 fit_policy, #policy for fitting BT\n",
    "                 tune_fit_policy,\n",
    "                 num_epochs, #number of BT fit epochs\n",
    "                 numfit, #number of tune_fit epochs\n",
    "                 ps=8192, #projection size\n",
    "                 n_in=3, #color channels\n",
    "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
    "                 outdim=9, #number of classes\n",
    "                 print_report=False, #F1 metrics etc\n",
    "                 print_plot=False, #ROC curve\n",
    "                 ):\n",
    "                 store_attr()\n",
    "                 self.vocab = self.dls_valid.vocab\n",
    "\n",
    "\n",
    "                 #self.encoder_path = f'/content/drive/My Drive/models/baselineencoder_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
    "                 #self.tuned_model_path = f'/content/drive/My Drive/models/baselinefinetuned_initial_weights={self.initial_weights}_pretrain={self.pretrain}.pth'\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(learn,fit_policy,epochs):\n",
    "\n",
    "        if fit_policy == 'fit':\n",
    "            learn.fit(epochs)\n",
    "        \n",
    "        elif fit_policy == 'fit_one_cycle':\n",
    "            learn.fit_one_cycle(epochs)\n",
    "       \n",
    "        elif fit_policy == 'fine_tune':\n",
    "            learn.fine_tune(epochs)\n",
    "\n",
    "        else: raise Exception('Fit policy not of expected form')\n",
    "\n",
    "\n",
    "    def train_encoder(self):\n",
    "        \"create encoder and (optionally, if pretrain=True) train with BT algorith, according to fit_policy\"\n",
    "\n",
    "\n",
    "        bt_model,encoder = create_model(which_model=self.initial_weights,device=device) #create encoder and bt model\n",
    "\n",
    "\n",
    "        if self.pretrain: #train encoder according to fit policy\n",
    "\n",
    "            learn = Learner(self.dls_train,bt_model, cbs=[BarlowTwins(self.aug_pipelines,n_in=self.n_in,lmb=1/self.ps,print_augs=False)])\n",
    "\n",
    "            main_train.fit(learn,self.fit_policy,epochs=self.num_epochs)\n",
    "\n",
    "            #torch.save(encoder.state_dict(), self.encoder_path)\n",
    "\n",
    "        self.encoder = bt_model.encoder\n",
    "\n",
    "\n",
    "    def fine_tune(self):\n",
    "        \"fine tune in supervised fashion, according to tune_fit_policy\"\n",
    "\n",
    "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
    "\n",
    "        model = LinearModel(encoder=self.encoder,indim=self.indim,outdim=self.outdim) #create 'linear' model (encoder + linear head)\n",
    "        \n",
    "        learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
    "\n",
    "        main_train.fit(learn,fit_policy=self.tune_fit_policy,epochs=self.numfit) #fine tuning (don't confuse this with fit policy!)\n",
    "\n",
    "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
    "\n",
    "        #metrics dict will have f1 score, auc etc etc\n",
    "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
    "        metrics['acc'] = acc\n",
    "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
    "        metrics['auc_dict'] = auc_dict\n",
    "\n",
    "        metrics['scores'] = scores\n",
    "        \n",
    "        #torch.save(model.state_dict(), self.tuned_model_path)\n",
    "        return metrics #\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        self.train_encoder() #train (or extract) the encoder\n",
    "        metrics = self.fine_tune()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "if __name__ == '__main__' and on_colab:\n",
    "\n",
    "\n",
    "    initialweights = ['bt_pretrain','supervised_pretrain']\n",
    "    fitpolicy = ['fit_one_cycle','fit']\n",
    "\n",
    "    #cartesian product of hps\n",
    "    MyTuple = namedtuple('MyTuple', 'initialweights fitpolicy')\n",
    "    HPs = [MyTuple(x,y) for x,y in list(itertools.product(initialweights, fitpolicy))]\n",
    "\n",
    "\n",
    "    for _ in range(1):\n",
    "\n",
    "        d={}\n",
    "        for initial_weights in initialweights:\n",
    "            metrics = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
    "                aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
    "                initial_weights='supervised_pretrain',pretrain=True,fit_policy='fit',tune_fit_policy='fine_tune',num_epochs=20,numfit=20, \n",
    "                )()\n",
    "\n",
    "            d[initial_weights] = {}\n",
    "\n",
    "            d[initial_weights]['acc'] = metrics['acc']\n",
    "\n",
    "            d[initial_weights]['scores'] = metrics['scores']\n",
    "\n",
    "            print(f\"With initial_weights={initial_weights}, acc is {d[initial_weights]['acc']}\")\n",
    "\n",
    "\n",
    "        ypred,acc = predict_ensemble(yval,scores1=d['bt_pretrain']['scores'],scores2=d['supervised_pretrain']['scores'])\n",
    "\n",
    "        print(f'Acc of ensemble is {acc}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    num=3\n",
    "    mean_acc = 0\n",
    "\n",
    "    for _ in range(num):\n",
    "        metrics = main_train(dls_train=dls_train,dls_tune=dls_tune,dls_valid=dls_valid, xval=xval, yval=yval,\n",
    "                    aug_pipelines=aug_pipelines, aug_pipelines_tune=aug_pipelines_tune, aug_pipelines_test=aug_pipelines_test, \n",
    "                    initial_weights='supervised_pretrain',pretrain=True,fit_policy='fit',tune_fit_policy='fine_tune',num_epochs=20,numfit=20, \n",
    "                    )()\n",
    "\n",
    "        acc = metrics['acc']\n",
    "        print(acc)\n",
    "        mean_acc += acc\n",
    "\n",
    "    print(mean_acc/num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
