{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cancer_maintrain_ensemble\n",
    "\n",
    "> Basic extensible API to train ensemble. Heavily builds on `cancer_maintrain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cancer_maintrain_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup: Surely there is a way to get rid of having to put this cell everywhere. hmmm.\n",
    "\n",
    "Or we can just copy paste / delete this in and out when needed. Either way, getting close to a decent workable workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def colab_is_true():\n",
    "\n",
    "    try: \n",
    "        from google.colab import drive\n",
    "\n",
    "        return True \n",
    "    except ModuleNotFoundError:\n",
    "        return False\n",
    "\n",
    "def setup_colab():\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    #os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"')\n",
    "    os.system('git clone https://github.com/hamish-haggerty/cancer-proj.git')\n",
    "    os.chdir('cancer-proj')\n",
    "    os.system('unzip -q \"/content/drive/My Drive/archive (1).zip\"') #does this work?\n",
    "    os.system('pip install -e .')\n",
    "    os.system('pip install -qU nbdev')\n",
    "    os.system('nbdev_install_quarto')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    on_colab = colab_is_true()\n",
    "    if on_colab:\n",
    "        setup_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamishhaggerty/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from fastai.vision.all import *\n",
    "from base_rbt.all import *\n",
    "from cancer_proj.cancer_dataloading import *\n",
    "from cancer_proj.cancer_metrics import *\n",
    "from cancer_proj.cancer_maintrain import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#Since we have cloned repository and cd'd into it (and the data itself is not stored in the\n",
    "#repo) we need cd out of it, get the data, then cd back into the repo `cancer-proj`.\n",
    "#This is a bit annoying, can maybe remove this later\n",
    "if on_colab:\n",
    "    #os.chdir('..') #assumes we are currently in cancer-proj directory\n",
    "    train_dir = colab_train_dir\n",
    "    test_dir = colab_test_dir\n",
    "else:\n",
    "    train_dir = local_train_dir\n",
    "    test_dir = local_test_dir\n",
    "\n",
    "#define general hps\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#bs=256\n",
    "#bs=698\n",
    "bs=256\n",
    "bs_tune=256\n",
    "size=128\n",
    "bs_val=174\n",
    "\n",
    "#get the data dictionary\n",
    "data_dict = get_fnames_dls_dict(train_dir=train_dir,test_dir=test_dir,\n",
    "                    device=device,bs_val=bs_val,bs=bs,bs_tune=bs_tune,size=size,n_in=3)\n",
    "\n",
    "#get the dataloaders\n",
    "dls_train,dls_tune,dls_valid = data_dict['dls_train'],data_dict['dls_tune'],data_dict['dls_valid']\n",
    "x,y = data_dict['x'],data_dict['y']\n",
    "xval,yval = data_dict['xval'],data_dict['yval']\n",
    "xtune,ytune = data_dict['xtune'],data_dict['ytune']\n",
    "vocab = data_dict['vocab']\n",
    "\n",
    "#If we want to write some tests (make sure the data is same every time etc):\n",
    "fnames,fnames_train,fnames_tune,fnames_valid,fnames_test = data_dict['fnames'],data_dict['fnames_train'],data_dict['fnames_tune'],data_dict['fnames_valid'],data_dict['fnames_test']\n",
    "\n",
    "test_eq(x.shape,xtune.shape)\n",
    "\n",
    "# if on_colab:\n",
    "#     os.chdir('cancer-proj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load aug pipelines here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "aug_dict = create_aug_pipelines(size=size,device=device,Augs=BYOL_Augs,TUNE_Augs=TUNE_Augs,Val_Augs=Val_Augs)\n",
    "aug_pipelines = aug_dict['aug_pipelines']\n",
    "aug_pipelines_tune = aug_dict['aug_pipelines_tune']\n",
    "aug_pipelines_test = aug_dict['aug_pipelines_test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class P4BarlowTwinsModel(Module):\n",
    "\n",
    "    def __init__(self,model,encoder2,projector2):\n",
    "        self.model = model #frozen model\n",
    "        self.encoder2 = encoder2\n",
    "        self.projector2 = projector2\n",
    "\n",
    "        #put on GPU\n",
    "        if torch.cuda.is_available(): self.to(torch.device('cuda'))\n",
    "\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        \n",
    "        enc = self.model.encoder(x)\n",
    "        enc2 = self.encoder2(x)\n",
    "\n",
    "        return self.model.projector(enc),self.projector2(enc2),enc,enc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_p4barlow_twins_model(model,encoder2, hidden_size=256, projection_size=128, bn=True, nlayers=3):\n",
    "    \"Create Barlow Twins model\"\n",
    "    n_in  = in_channels(encoder2)\n",
    "    with torch.no_grad(): \n",
    "        model.cpu()\n",
    "        encoder2.cpu()\n",
    "        \n",
    "        representation = encoder2(torch.randn((2,n_in,128,128)))\n",
    "\n",
    "    model.cpu()\n",
    "    encoder2.cpu()\n",
    "\n",
    "    projector2 = create_mlp_module(representation.size(1), hidden_size, projection_size, bn=bn, nlayers=nlayers) \n",
    "    apply_init(projector2)\n",
    "\n",
    "    return P4BarlowTwinsModel(model=model,encoder2=encoder2,projector2=projector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def show_btens_batch(dls,n_in,aug,n=2,print_augs=True):\n",
    "    \"Given a linear learner, show a batch\"\n",
    "        \n",
    "    learn = Learner(dls,model=None, cbs=[BarlowTwinsEns(aug,n_in=n_in,print_augs=print_augs)])\n",
    "    b = dls.one_batch()\n",
    "    learn._split(b)\n",
    "    learn('before_batch')\n",
    "    axes = learn.barlow_twins_ens.show(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_ens_model(model,device,ps=8192,n_in=3):\n",
    "    \"Input a barlow twins model (encoder and projector) that has already been trained\"\n",
    "\n",
    "    #Put into eval mode and turn off gradient\n",
    "    model.eval()\n",
    "    model = grad_on(model,on=False)\n",
    "\n",
    "    _,encoder2 = create_model('no_pretrain',device,ps=ps,n_in=3)\n",
    "    model2 = create_p4barlow_twins_model(model,encoder2,hidden_size=ps,projection_size=ps)\n",
    "\n",
    "    encoder2 = model2.encoder2\n",
    "    if device == 'cuda':\n",
    "        model2.cuda()\n",
    "        encoder2.cuda()\n",
    "\n",
    "\n",
    "    return model2,encoder2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cov_mat(Z1,Z2):\n",
    "    \"Generally, we assume that has already been normalized\"\n",
    "\n",
    "    bs=Z1.shape[0]\n",
    "\n",
    "    return (Z1.T @ Z2) / bs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of loss functions (type 1 and type 2). Each of these can be further computed in encoder or projector space. Type 1 is closer to standard RR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "    \n",
    "def lf_1_enc(pred,I,lmb,\n",
    "               t,\n",
    "               s,\n",
    "               ):\n",
    "    \n",
    "    \"compute `standard` rr in proj-encoder space\"\n",
    "    pred1 = pred[0] #frozen\n",
    "    pred2 = pred[1] #has gradients\n",
    "\n",
    "    pred1_enc = pred[2]\n",
    "    pred2_enc = pred[3]\n",
    "    \n",
    "    \n",
    "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
    "    \n",
    "    z1_2, z2_2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm_2 = (z1_2 - z1_2.mean(0)) / (z1_2.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm_2 = (z2_2 - z2_2.mean(0)) / (z2_2.std(0, unbiased=False) + 1e-7)\n",
    "\n",
    "    \n",
    "    z1, z2 = pred1_enc[:bs],pred1_enc[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm_enc = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm_enc = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
    "\n",
    "    #We don't actually need encoder for unfrozen model, I believe, at this point.\n",
    "    \n",
    "    #Make sure gradients are turned off / turned on appropriately\n",
    "    test_eq(pred1.requires_grad,False)\n",
    "    test_eq(pred2.requires_grad,True)\n",
    "\n",
    "    # #Within frozen model \n",
    "    # C = (z1norm.T @ z2norm) / bs \n",
    "    # cdiff = (C - I)**2\n",
    "    \n",
    "    #Within model_2 (unfrozen)\n",
    "    C2 = (z1norm_2.T @ z2norm_2) / bs \n",
    "    cdiff_2 = (C2 - I)**2\n",
    "\n",
    "\n",
    "    #split projector of unfrozen model up into 3 groups. We will compare each guy to the encoder\n",
    "    z1norm_21,z1norm_22,z1norm_23,z1norm_24 = z1norm_2[:,0:2048],z1norm_2[:,2048:4096],z1norm_2[:,4096:6144],z1norm_2[:,6144:8192]\n",
    "    z2norm_21,z2norm_22,z2norm_23,z2norm_24 = z2norm_2[:,0:2048],z2norm_2[:,2048:4096],z2norm_2[:,4096:6144],z2norm_2[:,6144:8192]\n",
    "\n",
    "    #between model for rr. \n",
    "    C_rr11,C_rr12,C_rr13,C_rr14 = cov_mat(z1norm_enc,z1norm_21), cov_mat(z1norm_enc,z1norm_22),cov_mat(z1norm_enc,z1norm_23),cov_mat(z1norm_enc,z1norm_24)\n",
    "    cdiff_rr_1 = (1/4)*(C_rr11.pow(2) + C_rr12.pow(2) + C_rr13.pow(2) + C_rr14.pow(2))\n",
    "\n",
    "    C_rr21,C_rr22,C_rr23,C_rr24 = cov_mat(z2norm_enc,z2norm_21), cov_mat(z2norm_enc,z2norm_22),cov_mat(z2norm_enc,z2norm_23),cov_mat(z2norm_enc,z2norm_24)\n",
    "    cdiff_rr_2 = (1/4)*(C_rr21.pow(2) + C_rr22.pow(2) + C_rr23.pow(2) + C_rr24.pow(2))\n",
    "\n",
    "    cdiff_rr = 0.5*(cdiff_rr_1 + cdiff_rr_2)\n",
    "\n",
    "    I_enc = torch.eye(2048).cuda()\n",
    "\n",
    "    #between model for inv\n",
    "    C_inva1 = (z1norm.T @ z2norm_2) / bs\n",
    "    cdiff_inva_1 = (C_inva1+I).pow(2)\n",
    "\n",
    "    C_inva2 = (z2norm.T @ z1norm_2) / bs\n",
    "    cdiff_inva_2 = (C_inva2+I).pow(2)\n",
    "\n",
    "    cdiff_inva = 0.5*(cdiff_inva_1 + cdiff_inva_2)\n",
    "\n",
    "    loss = (1-t)*(cdiff_2*I).sum() + t*(cdiff_inva*I).sum() + (1-s)*lmb*(cdiff_2*(1-I)).sum() + s*lmb*(cdiff_rr*(1-I_enc)).sum()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def lf_1_proj(pred,I,lmb,\n",
    "               t,\n",
    "               s,\n",
    "               ):\n",
    "    \"type 1 loss in projector space\"\n",
    "\n",
    "    \n",
    "    pred1 = pred[0] #frozen\n",
    "    pred2 = pred[1] #has gradients\n",
    "    \n",
    "    \n",
    "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
    "    \n",
    "    z1_2, z2_2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm_2 = (z1_2 - z1_2.mean(0)) / (z1_2.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm_2 = (z2_2 - z2_2.mean(0)) / (z2_2.std(0, unbiased=False) + 1e-7)\n",
    "    \n",
    "    #Make sure gradients are turned off / turned on appropriately\n",
    "    test_eq(pred1.requires_grad,False)\n",
    "    test_eq(pred2.requires_grad,True)\n",
    "\n",
    "    # #Within frozen model \n",
    "    # C = (z1norm.T @ z2norm) / bs \n",
    "    # cdiff = (C - I)**2\n",
    "    \n",
    "    #Within model_2 (unfrozen)\n",
    "    C2 = (z1norm_2.T @ z2norm_2) / bs \n",
    "    cdiff_2 = (C2 - I)**2\n",
    "\n",
    "    #between model for rr\n",
    "    C_rr1=(z1norm.T @ z1norm_2) / bs\n",
    "    cdiff_rr_1 = C_rr1.pow(2)\n",
    "\n",
    "    C_rr2=(z2norm.T @ z2norm_2) / bs\n",
    "    cdiff_rr_2 = C_rr2.pow(2)\n",
    "\n",
    "    cdiff_rr = 0.5*(cdiff_rr_1 + cdiff_rr_2)\n",
    "\n",
    "    #between model for inv\n",
    "    C_inva1 = (z1norm.T @ z2norm_2) / bs\n",
    "    cdiff_inva_1 = (C_inva1+I).pow(2)\n",
    "\n",
    "    C_inva2 = (z2norm.T @ z1norm_2) / bs\n",
    "    cdiff_inva_2 = (C_inva2+I).pow(2)\n",
    "\n",
    "    cdiff_inva = 0.5*(cdiff_inva_1 + cdiff_inva_2)\n",
    "\n",
    "\n",
    "    loss = (1-t)*(cdiff_2*I).sum() + t*(cdiff_inva*I).sum() + (1-s)*lmb*(cdiff_2*(1-I)).sum() + s*lmb*(cdiff_rr*(1-I)).sum()\n",
    "\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def lf_2_enc(pred,I,lmb,\n",
    "               t,\n",
    "               s,\n",
    "               ):\n",
    "    \n",
    "    \"type 2 loss in encoder space\"\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    pred1 = pred[0] #frozen\n",
    "    pred2 = pred[1] #has gradients\n",
    "\n",
    "    pred1_enc = pred[2]\n",
    "    #pred2_enc = pred[3] #don't actually use this guy\n",
    "    \n",
    "    \n",
    "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
    "    \n",
    "    z1_2, z2_2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm_2 = (z1_2 - z1_2.mean(0)) / (z1_2.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm_2 = (z2_2 - z2_2.mean(0)) / (z2_2.std(0, unbiased=False) + 1e-7)\n",
    "\n",
    "    \n",
    "    z1, z2 = pred1_enc[:bs],pred1_enc[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm_enc = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm_enc = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
    "\n",
    "    #We don't actually need encoder for unfrozen model, I believe, at this point.\n",
    "    \n",
    "    #Make sure gradients are turned off / turned on appropriately\n",
    "    test_eq(pred1.requires_grad,False)\n",
    "    test_eq(pred2.requires_grad,True)\n",
    "\n",
    "    # #Within frozen model \n",
    "    # C = (z1norm.T @ z2norm) / bs \n",
    "    # cdiff = (C - I)**2\n",
    "    \n",
    "    #Within model_2 (unfrozen)\n",
    "    C2 = (z1norm_2.T @ z2norm_2) / bs \n",
    "    cdiff_2 = (C2 - I)**2\n",
    "\n",
    "\n",
    "    #split projector of unfrozen model up into 3 groups. We will compare each guy to the encoder\n",
    "    z1norm_21,z1norm_22,z1norm_23,z1norm_24 = z1norm_2[:,0:2048],z1norm_2[:,2048:4096],z1norm_2[:,4096:6144],z1norm_2[:,6144:8192]\n",
    "    z2norm_21,z2norm_22,z2norm_23,z2norm_24 = z2norm_2[:,0:2048],z2norm_2[:,2048:4096],z2norm_2[:,4096:6144],z2norm_2[:,6144:8192]\n",
    "\n",
    "    #yes, we can make this code nicer\n",
    "\n",
    "    t1 = z1norm_enc*z1norm_21 #like z^A1 * Z^A2 ...\n",
    "    t2 = z2norm_enc*z2norm_21\n",
    "    C_rr_1 = t1.T @ t2 / bs\n",
    "\n",
    "    t1 = z1norm_enc*z1norm_22 #like z^A1 * Z^A2 ...\n",
    "    t2 = z2norm_enc*z2norm_22\n",
    "    C_rr_2 = t1.T @ t2 / bs\n",
    "\n",
    "    t1 = z1norm_enc*z1norm_23 #like z^A1 * Z^A2 ...\n",
    "    t2 = z2norm_enc*z2norm_23\n",
    "    C_rr_3 = t1.T @ t2 / bs\n",
    "\n",
    "    t1 = z1norm_enc*z1norm_24 #like z^A1 * Z^A2 ...\n",
    "    t2 = z2norm_enc*z2norm_24\n",
    "    C_rr_4 = t1.T @ t2 / bs\n",
    "\n",
    "    cdiff_rr = (1/4)*((C_rr_1.pow(2) + 1e-7).pow(0.5) + (C_rr_2.pow(2) + 1e-7).pow(0.5) + (C_rr_3.pow(2) + 1e-7).pow(0.5) + (C_rr_4.pow(2) + 1e-7).pow(0.5))  #keep the units the same\n",
    "\n",
    "    I_enc = torch.eye(2048).cuda()\n",
    "\n",
    "    #between model for inv\n",
    "    C_inva1 = (z1norm.T @ z2norm_2) / bs\n",
    "    cdiff_inva_1 = (C_inva1-I).pow(2)\n",
    "\n",
    "    C_inva2 = (z2norm.T @ z1norm_2) / bs\n",
    "    cdiff_inva_2 = (C_inva2-I).pow(2)\n",
    "\n",
    "    cdiff_inva = 0.5*(cdiff_inva_1 + cdiff_inva_2)\n",
    "\n",
    "    loss = (1-t)*(cdiff_2*I).sum() + t*(cdiff_inva*I).sum() + (1-s)*lmb*(cdiff_2*(1-I)).sum() + s*lmb*(cdiff_rr*(1-I_enc)).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def lf_2_proj(pred,I,lmb,\n",
    "               t,\n",
    "               s,\n",
    "               ):\n",
    "    \"Type 2 loss in projector space\"\n",
    "\n",
    "    \n",
    "    pred1 = pred[0] #frozen\n",
    "    pred2 = pred[1] #has gradients\n",
    "    \n",
    "    \n",
    "    bs,nf = pred1.size(0)//2,pred1.size(1)\n",
    "\n",
    "    #All standard, from BT\n",
    "    z1, z2 = pred1[:bs],pred1[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm = (z1 - z1.mean(0)) / (z1.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm = (z2 - z2.mean(0)) / (z2.std(0, unbiased=False) + 1e-7)\n",
    "    \n",
    "    z1_2, z2_2 = pred2[:bs],pred2[bs:] #so z1 is bs*projection_size, likewise for z2\n",
    "    z1norm_2 = (z1_2 - z1_2.mean(0)) / (z1_2.std(0, unbiased=False) + 1e-7)\n",
    "    z2norm_2 = (z2_2 - z2_2.mean(0)) / (z2_2.std(0, unbiased=False) + 1e-7)\n",
    "    \n",
    "    #Make sure gradients are turned off / turned on appropriately\n",
    "    test_eq(pred1.requires_grad,False)\n",
    "    test_eq(pred2.requires_grad,True)\n",
    "\n",
    "    # #Within frozen model \n",
    "    # C = (z1norm.T @ z2norm) / bs \n",
    "    # cdiff = (C - I)**2\n",
    "    \n",
    "    #Within model_2 (unfrozen)\n",
    "    C2 = (z1norm_2.T @ z2norm_2) / bs \n",
    "    cdiff_2 = (C2 - I)**2\n",
    "\n",
    "    #between model for rr\n",
    "    # C_rr1=(z1norm.T @ z1norm_2) / bs\n",
    "    # cdiff_rr_1 = C_rr1.pow(2)\n",
    "\n",
    "    # C_rr2=(z2norm.T @ z2norm_2) / bs\n",
    "    # cdiff_rr_2 = C_rr2.pow(2)\n",
    "\n",
    "    # cdiff_rr = 0.5*(cdiff_rr_1 + cdiff_rr_2)\n",
    "\n",
    "    t1 = z1norm*z1norm_2 #like z^A1 * Z^A2 ...\n",
    "    t2 = z2norm*z2norm_2\n",
    "\n",
    "    C_rr = t1.T @ t2 / bs\n",
    "\n",
    "    cdiff_rr = (C_rr.pow(2) + 1e-7).pow(0.5) #keep the units the same\n",
    "\n",
    "\n",
    "    #between model for inv\n",
    "    C_inva1 = (z1norm.T @ z2norm_2) / bs\n",
    "    cdiff_inva_1 = (C_inva1-I).pow(2)\n",
    "\n",
    "    C_inva2 = (z2norm.T @ z1norm_2) / bs\n",
    "    cdiff_inva_2 = (C_inva2-I).pow(2)\n",
    "\n",
    "    cdiff_inva = 0.5*(cdiff_inva_1 + cdiff_inva_2)\n",
    "\n",
    "\n",
    "    loss = (1-t)*(cdiff_2*I).sum() + t*(cdiff_inva*I).sum() + (1-s)*lmb*(cdiff_2*(1-I)).sum() + s*lmb*(cdiff_rr*(1-I)).sum()\n",
    "\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class main_train_ensemble(main_train):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dls_train, #used for training BT (if pretrain=True)\n",
    "                 dls_tune , #used for tuning\n",
    "                 dls_valid, #used to compute metrics / evaluate results. \n",
    "                 xval, #currently `predict_model` below assumes this is entire validation / test data\n",
    "                 yval,\n",
    "                 aug_pipelines, #the aug pipeline for self-supervised learning\n",
    "                 aug_pipelines_tune, #the aug pipeline for supervised learning\n",
    "                 aug_pipelines_test, #test (or valid) time augmentations \n",
    "                 initial_weights, #Which initial weights to use\n",
    "                 pretrain, #Whether to fit BT\n",
    "                 num_epochs, #number of BT fit epochs\n",
    "                 numfit, #number of tune_fit epochs\n",
    "                 freeze_num_epochs, #How many epochs to freeze body for when training BT\n",
    "                 freeze_numfit, #How many epochs to freeze body for when fine tuning\n",
    "                 ps=8192, #projection size\n",
    "                 n_in=3, #color channels\n",
    "                 indim=2048, #dimension output of encoder (2048 for resnet50)\n",
    "                 outdim=9, #number of classes\n",
    "                 print_report=False, #F1 metrics etc\n",
    "                 print_plot=False, #ROC curve\n",
    "                 tune_model_path=None, #save models after fine tuning\n",
    "                 model=None, #BT model that has already been trained; i.e. what we are pushing rep away from...\n",
    "                 ):\n",
    "        store_attr()\n",
    "        self.vocab = self.dls_valid.vocab\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "    def fit(learn,fit_type,epochs,freeze_epochs,initial_weights,pretrain):\n",
    "        \"\"\"We can patch in a modification, e.g. if we want subtype of fine_tune:supervised_pretrain to be different\n",
    "        to fine_tune:bt_pretrain\"\"\"\n",
    "\n",
    "        if fit_type == 'encoder_fine_tune': #i.e. barlow twins\n",
    "\n",
    "            #learn.encoder_fine_tune(epochs,freeze_epochs=freeze_epochs)\n",
    "            lr_max=0.0030199517495930195\n",
    "            print(f'lr_max={lr_max}')\n",
    "            learn.fit_one_cycle(epochs,lr_max= lr_max)\n",
    "\n",
    "        elif fit_type == 'fine_tune':\n",
    "\n",
    "            if pretrain == False:\n",
    "                print('pretrain was False, and about to fit_one_cycle')\n",
    "                learn.fit_one_cycle(epochs,lr_max=0.00027542) \n",
    "\n",
    "            elif pretrain == True:\n",
    "                print('pretrain was True, and about to linear_fine_tune')\n",
    "                learn.linear_fine_tune(epochs,freeze_epochs=freeze_epochs) #This gave very similar performance, when pretrain=False (see above / earlier commit)\n",
    "\n",
    "            #learn.no_freeze_linear_fine_tune(epochs,freeze_epochs=freeze_epochs) \n",
    "\n",
    "        else: raise Exception('Fit policy not of expected form')\n",
    "\n",
    "    def train_encoder(self):\n",
    "        \"create encoder and (optionally, if pretrain=True) train with BT algorithm, according to fit_policy\"\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            bt_model2,encoder2 = create_ens_model(model=self.model,ps=self.ps,device=self.device)\n",
    "\n",
    "        if self.pretrain: #train encoder according to fit policy\n",
    "\n",
    "            lmb=1/8192\n",
    "            learn = Learner(self.dls_train,bt_model2,cbs=[BarlowTwinsEns(self.aug_pipelines,n_in=self.n_in,lmb=lmb,print_augs=False)])\n",
    "            main_train_ensemble.fit(learn,fit_type='encoder_fine_tune',\n",
    "                            epochs=self.num_epochs,freeze_epochs=self.freeze_num_epochs,\n",
    "                            initial_weights=self.initial_weights,\n",
    "                            pretrain=self.pretrain\n",
    "                            )\n",
    "            \n",
    "        self.encoder2 = bt_model2.encoder2\n",
    "        self.bt_model2=bt_model2\n",
    "\n",
    "\n",
    "    def fine_tune(self):\n",
    "        \"fine tune in supervised fashion, according to tune_fit_policy, and get metrics\"\n",
    "\n",
    "        #encoder = pickle.loads(pickle.dumps(self.encoder)) #We might want to pretrain once and fine tune several times (varying e.g. tune augs)\n",
    "\n",
    "\n",
    "        model = LM(self.encoder2)\n",
    "        learn = Learner(self.dls_tune,model,splitter=my_splitter,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
    "\n",
    "        #debugging\n",
    "        #learn = Learner(self.dls_tune,model,cbs = [LinearBt(aug_pipelines=self.aug_pipelines_tune,n_in=self.n_in)],wd=0.0)\n",
    "\n",
    "        main_train_ensemble.fit(learn,fit_type='fine_tune',\n",
    "                    epochs=self.numfit,freeze_epochs=self.freeze_numfit,\n",
    "                    initial_weights=self.initial_weights,\n",
    "                    pretrain=self.pretrain\n",
    "                    ) #fine tuning (don't confuse this with fit policy!)\n",
    "        \n",
    "        scores,preds, acc = predict_model(self.xval,self.yval,model=model,aug_pipelines_test=self.aug_pipelines_test,numavg=3)\n",
    "        #metrics dict will have f1 score, auc etc etc\n",
    "        metrics = classification_report_wrapper(preds, self.yval, self.vocab, print_report=self.print_report)\n",
    "        auc_dict = plot_roc(self.yval,preds,self.vocab,print_plot=self.print_plot)\n",
    "        metrics['acc'],metrics['auc_dict'],metrics['scores'],metrics['preds'],metrics['xval'],metrics['yval'] = acc,auc_dict,scores,preds,self.xval,self.yval\n",
    "\n",
    "        if self.tune_model_path != None:\n",
    "            metrics['classif_model_path'] = self.tune_model_path\n",
    "            torch.save(model.state_dict(), self.tune_model_path)\n",
    "\n",
    "\n",
    "        return metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
